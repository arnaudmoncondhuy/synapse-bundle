# Configuration Avanc√©e - SynapseBundle

Documentation compl√®te des param√®tres avanc√©s de configuration pour l'int√©gration Gemini via Vertex AI.

## Table des mati√®res

1. [Configuration de Base](#configuration-de-base)
2. [Filtres de S√©curit√© (Safety Settings)](#filtres-de-s√©curit√©-safety-settings)
3. [Configuration de G√©n√©ration (Generation Config)](#configuration-de-g√©n√©ration-generation-config)
4. [Context Caching](#context-caching)
5. [Exemples Complets](#exemples-complets)

---

## Configuration de Base

### Mod√®le et Authentification

```yaml
synapse:
    # Mod√®le Gemini √† utiliser (tous les mod√®les Vertex AI support√©s)
    model: 'gemini-2.5-flash'

    # Configuration Vertex AI
    vertex:
        project_id: 'your-gcp-project-id'
        region: 'europe-west1'
        service_account_json: '%kernel.project_dir%/config/secrets/gcp-service-account.json'

    # R√©flexion native (CoT - Chain of Thought)
    thinking:
        enabled: true
        budget: 2048  # Tokens allou√©s pour la r√©flexion interne
```

---

## Filtres de S√©curit√© (Safety Settings)

### Description

Les **filtres de s√©curit√©** permettent de contr√¥ler le contenu g√©n√©r√© par le mod√®le. Ils sont particuli√®rement utiles dans un environnement scolaire pour bloquer les contenus inadapt√©s.

Vertex AI propose 4 cat√©gories de contenu √† filtrer :

| Cat√©gorie | Description |
|-----------|-------------|
| `hate_speech` | Discours haineux, discrimination |
| `dangerous_content` | Contenu dangereux (instructions d'armes, drogues, etc.) |
| `harassment` | Harc√®lement, contenu abusif |
| `sexually_explicit` | Contenu sexuel explicite |

### Seuils de Blocage

| Seuil | Signification |
|-------|---------------|
| `BLOCK_NONE` | Aucun blocage |
| `BLOCK_ONLY_HIGH` | Bloque seulement les probabilit√©s tr√®s √©lev√©es |
| `BLOCK_MEDIUM_AND_ABOVE` | **RECOMMAND√â pour les √©tablissements** - Bloque moyen, √©lev√© et tr√®s √©lev√© |
| `BLOCK_LOW_AND_ABOVE` | Tr√®s restrictif - Bloque m√™me les faibles probabilit√©s |

### Configuration

```yaml
synapse:
    safety_settings:
        # Activer les filtres de s√©curit√©
        enabled: true

        # Seuil par d√©faut pour toutes les cat√©gories
        default_threshold: 'BLOCK_MEDIUM_AND_ABOVE'

        # Seuils sp√©cifiques par cat√©gorie (optionnel)
        # Si non sp√©cifi√©, utilise le seuil par d√©faut
        thresholds:
            hate_speech: 'BLOCK_MEDIUM_AND_ABOVE'
            dangerous_content: 'BLOCK_MEDIUM_AND_ABOVE'
            harassment: 'BLOCK_MEDIUM_AND_ABOVE'
            sexually_explicit: 'BLOCK_MEDIUM_AND_ABOVE'
```

### Exemple pour un Lyc√©e

```yaml
synapse:
    safety_settings:
        enabled: true
        default_threshold: 'BLOCK_MEDIUM_AND_ABOVE'
        thresholds:
            hate_speech: 'BLOCK_LOW_AND_ABOVE'        # Plus strict
            dangerous_content: 'BLOCK_MEDIUM_AND_ABOVE'
            harassment: 'BLOCK_MEDIUM_AND_ABOVE'
            sexually_explicit: 'BLOCK_LOW_AND_ABOVE'   # Plus strict
```

### Comportement

Quand un filtre de s√©curit√© bloque le contenu :
- La r√©ponse est vide ou minimale
- Un message d'erreur est retourn√©
- Aucune r√©flexion (thinking) n'est expos√©e si elle contient le contenu bloqu√©

---

## Configuration de G√©n√©ration (Generation Config)

### Description

Les **param√®tres de g√©n√©ration** contr√¥lent le comportement du mod√®le lors de la g√©n√©ration de r√©ponses.

### Param√®tres

| Param√®tre | Plage | D√©faut | Description |
|-----------|-------|--------|-------------|
| `temperature` | 0.0 - 2.0 | 1.0 | Contr√¥le la cr√©ativit√©. 0.0 = d√©terministe, 2.0 = tr√®s cr√©atif |
| `top_p` | 0.0 - 1.0 | 0.95 | Nucleus sampling : probabilit√© cumulative des tokens consid√©r√©s |
| `top_k` | ‚â• 1 | 40 | Nombre de tokens avec la plus haute probabilit√© √† consid√©rer |
| `max_output_tokens` | ‚â• 1 | null* | Limite maximale de tokens g√©n√©r√©s (null = d√©faut du mod√®le) |
| `stop_sequences` | Array | [] | S√©quences qui arr√™tent la g√©n√©ration (ex: `["\\n\\n"]`) |

*null signifie que le mod√®le utilise sa limite par d√©faut (ex: 8000 tokens pour gemini-2.5-flash)

### Configuration

```yaml
synapse:
    generation_config:
        # Temp√©rature : 0.0 (d√©terministe) √† 2.0 (cr√©atif)
        temperature: 1.0

        # Nucleus sampling (0.0 √† 1.0)
        top_p: 0.95

        # Top-K (nombre minimum 1)
        top_k: 40

        # Limite de tokens de sortie
        max_output_tokens: null  # null = par d√©faut du mod√®le

        # S√©quences d'arr√™t personnalis√©es
        stop_sequences: []
```

### Cas d'Usage Courants

#### 1. R√©ponses D√©terministes (Exercices d'Analyse)

```yaml
synapse:
    generation_config:
        temperature: 0.2          # Faible cr√©ativit√©
        top_p: 0.9
        top_k: 20
        max_output_tokens: 2000   # Limite les bavardages
```

#### 2. R√©ponses Cr√©atives (Brainstorming)

```yaml
synapse:
    generation_config:
        temperature: 1.5          # Cr√©atif
        top_p: 0.98
        top_k: 50
        max_output_tokens: 4000
```

#### 3. R√©sum√©s Courts

```yaml
synapse:
    generation_config:
        temperature: 0.8
        top_p: 0.95
        top_k: 40
        max_output_tokens: 500    # Force la concision
        stop_sequences:           # Arr√™te apr√®s 2 retours √† la ligne
            - "\n\n"
```

#### 4. Explications P√©dagogiques

```yaml
synapse:
    generation_config:
        temperature: 0.7
        top_p: 0.9
        top_k: 30
        max_output_tokens: 3000
        stop_sequences: []        # Pas d'arr√™t forc√©
```

---

## Context Caching

### Description

Le **Context Caching** (mise en cache de contexte) permet de :
- **R√©duire les co√ªts** : 90% de r√©duction sur les tokens en cache
- **Acc√©l√©rer les r√©ponses** : Les contenus en cache sont trait√©s plus rapidement
- **R√©utiliser du contexte** : Parfait pour les documents volumineux, proc√©dures, etc.

### Cas d'Usage au Lyc√©e

- üìö **Proc√©dures scolaires** : R√®glement int√©rieur, protocoles
- üìñ **Documents volumineux** : Trait√©s en cache pour analyse r√©p√©t√©e
- üî¨ **√ânonc√©s d'exercices** : R√©utiliser le m√™me √©nonc√© pour plusieurs questions
- üìã **Ressources p√©dagogiques** : Chapitre de manuel pour plusieurs discussions

### Configuration

```yaml
synapse:
    context_caching:
        # Activer la fonctionnalit√©
        enabled: false

        # ID du contenu en cache (cr√©√© via l'API Vertex AI)
        cached_content_id: null
```

### Cr√©er un Cache

Le caching n√©cessite une √©tape pr√©alable : cr√©er le cache via l'API Vertex AI.

#### Exemple : Cacher un Document

```php
// Dans votre contr√¥leur ou service
$geminiClient->cacheContent(
    systemInstruction: "Tu es un assistant p√©dagogique.",
    cachedContent: "Contenu volumineux √† cacher (ex: chapitre complet)",
    timeToLive: 3600  // 1 heure
);
// Retourne: ['cachedContent' => 'projects/.../cachedContents/xyz123...']
```

Utilisez ensuite l'ID retourn√© dans la configuration :

```yaml
synapse:
    context_caching:
        enabled: true
        cached_content_id: 'projects/your-project/locations/europe-west1/cachedContents/xyz123...'
```

### Limites et Contraintes

| Aspect | D√©tail |
|--------|--------|
| **Minimum** | 2,048 tokens |
| **Maximum** | Jusqu'√† la limite du mod√®le (Gemini 2.5 Pro : 1M+ tokens) |
| **TTL** | 1 heure (renouvellement automatique √† chaque acc√®s) |
| **Co√ªt** | 5 √ó moins cher que les tokens normaux |
| **Dur√©e** | Disponible 1 heure apr√®s cr√©ation |

### Exemple Complet

```yaml
synapse:
    model: 'gemini-2.5-flash'

    vertex:
        project_id: 'intranet-lycee-485610'
        region: 'europe-west1'
        service_account_json: '%kernel.project_dir%/config/secrets/gcp-service-account.json'

    thinking:
        enabled: true
        budget: 2048

    # Cacher le r√®glement int√©rieur pour analyse r√©p√©t√©e
    context_caching:
        enabled: true
        cached_content_id: 'projects/intranet-lycee-485610/locations/europe-west1/cachedContents/abc123def456'
```

---

## Exemples Complets

### Configuration Minimale (Production)

```yaml
synapse:
    model: 'gemini-2.5-flash'

    vertex:
        project_id: 'your-gcp-project'
        region: 'europe-west1'
        service_account_json: '%kernel.project_dir%/config/secrets/gcp-service-account.json'

    thinking:
        enabled: true
        budget: 2048
```

### Configuration Lyc√©e (S√©curis√©e)

```yaml
synapse:
    model: 'gemini-2.5-flash'

    vertex:
        project_id: 'intranet-lycee-485610'
        region: 'europe-west1'
        service_account_json: '%kernel.project_dir%/config/secrets/gcp-service-account.json'

    thinking:
        enabled: true
        budget: 2048

    # Filtres de s√©curit√© activ√©s
    safety_settings:
        enabled: true
        default_threshold: 'BLOCK_MEDIUM_AND_ABOVE'

    # G√©n√©ration √©quilibr√©e
    generation_config:
        temperature: 1.0
        top_p: 0.95
        top_k: 40
        max_output_tokens: null
```

### Configuration Avanc√©e (Tous les Param√®tres)

```yaml
synapse:
    model: 'gemini-2.5-flash'

    vertex:
        project_id: 'intranet-lycee-485610'
        region: 'europe-west1'
        service_account_json: '%kernel.project_dir%/config/secrets/gcp-service-account.json'

    thinking:
        enabled: true
        budget: 2048

    safety_settings:
        enabled: true
        default_threshold: 'BLOCK_MEDIUM_AND_ABOVE'
        thresholds:
            hate_speech: 'BLOCK_LOW_AND_ABOVE'
            dangerous_content: 'BLOCK_MEDIUM_AND_ABOVE'
            harassment: 'BLOCK_MEDIUM_AND_ABOVE'
            sexually_explicit: 'BLOCK_LOW_AND_ABOVE'

    generation_config:
        temperature: 0.8
        top_p: 0.9
        top_k: 30
        max_output_tokens: 3000
        stop_sequences:
            - "\n\nQuestion :"

    context_caching:
        enabled: true
        cached_content_id: 'projects/intranet-lycee-485610/locations/europe-west1/cachedContents/abc123'
```

---

## Notes Importantes

### Performance

- **Safety Settings** : Ajoute ~10-20ms √† chaque requ√™te (acceptable)
- **Context Caching** : √âconomise 10-20% de latence sur requ√™tes r√©p√©t√©es
- **Generation Config** : Les limites `max_output_tokens` r√©duisent la latence

### Co√ªts Google Cloud

- **Tokens normaux** : Prix standard par mod√®le
- **Tokens en cache** : 90% moins chers (~5√ó r√©duction effective avec overhead)
- **Safety Processing** : Inclus dans le prix (pas de surco√ªt)

### S√©curit√© au Lyc√©e

Recommandations :
1. Toujours activer `safety_settings` avec `BLOCK_MEDIUM_AND_ABOVE`
2. Pour du contenu sensible, utiliser `BLOCK_LOW_AND_ABOVE`
3. Tester avec des cas limites avant d√©ploiement
4. Monitorer les r√©ponses bloqu√©es dans les logs

---

## D√©pannage

### Les filtres de s√©curit√© bloquent des r√©ponses l√©gitimes

‚ûú Diminuer le seuil de blocage par cat√©gorie :
```yaml
safety_settings:
    thresholds:
        hate_speech: 'BLOCK_MEDIUM_AND_ABOVE'  # au lieu de BLOCK_LOW_AND_ABOVE
```

### Le context caching n'est pas utilis√©

‚ûú V√©rifier que :
1. `context_caching.enabled: true`
2. `cached_content_id` est d√©fini et valide (commence par `projects/`)
3. Le contenu en cache n'a pas expir√© (1 heure max)

### Les r√©ponses sont trop courtes ou coup√©es

‚ûú Augmenter `max_output_tokens` ou le mettre √† `null` :
```yaml
generation_config:
    max_output_tokens: null  # Utilise le maximum du mod√®le
```

---

**Derni√®re mise √† jour** : 2026-01-27
**Version Bundle** : Compatible avec Gemini 2.5 Flash / Pro via Vertex AI
