# SynapseBundle

Un bundle Symfony pour intÃ©grer facilement des assistants IA dans votre application, avec support multi-providers (Google Gemini, OVH AI Endpoints) et interface d'administration complÃ¨te.

> **ğŸ“£ FÃ©vrier 2026** : Standardisation sur le format OpenAI pour 100% d'agnostisme LLM.
> Si vous avez crÃ©Ã© un client personnalisÃ©, consultez [IMPLEMENTATION_GUIDE.md](IMPLEMENTATION_GUIDE.md) et le [Changelog](docs/changelog.md#-breaking-changes---standardisation-openai) pour les breaking changes.

## âœ¨ FonctionnalitÃ©s

- ğŸ¤– **Multi-providers** : Google Vertex AI (Gemini 2.5+) et OVH AI Endpoints (OpenAI-compatible)
- ğŸ”§ **Function Calling** : SystÃ¨me extensible pour ajouter des outils IA personnalisÃ©s
- ğŸ“¡ **Streaming** : RÃ©ponses en temps rÃ©el via NDJSON
- ğŸ’¾ **Persistance** : Historique des conversations en base de donnÃ©es (Doctrine)
- ğŸ”’ **SÃ©curitÃ©** :
  - Chiffrement des messages (XSalsa20-Poly1305)
  - Chiffrement des credentials des providers
  - Filtres de sÃ©curitÃ© configurables
- ğŸ¨ **Interface Admin** : Dashboard, analytiques, gestion des presets et modÃ¨les
- ğŸ¯ **Personas** : PersonnalitÃ©s IA prÃ©dÃ©finies ou custom
- ğŸ’­ **Thinking Mode** : Support natif du raisonnement Chain-of-Thought (Gemini 2.5+)
- ğŸ“Š **Token Tracking** : Suivi de la consommation et calcul des coÃ»ts
- ğŸ§© **Modes flexibles** : Standalone ou intÃ©gration dans votre design system

## ğŸ“‹ PrÃ©requis

- **PHP** : 8.2 ou supÃ©rieur
- **Symfony** : 7.0 ou supÃ©rieur
- **Extension PHP** : `sodium` (pour le chiffrement)
- **Provider LLM** :
  - Google Cloud avec Vertex AI activÃ© (pour Gemini), OU
  - Compte OVH avec accÃ¨s aux AI Endpoints

## ğŸš€ Installation

```bash
composer require arnaudmoncondhuy/synapse-bundle
```

## âš™ï¸ Configuration minimale

```yaml
# config/packages/synapse.yaml
synapse:
    persistence:
        enabled: true
        handler: doctrine
        conversation_class: App\Entity\Conversation
        message_class: App\Entity\Message

    admin:
        enabled: true
```

Pour plus d'options, voir [Configuration](docs/configuration.md).

## ğŸ“– Usage rapide

### 1. Widget de chat (Plug-and-play)

```twig
{# templates/page.html.twig #}
{{ include('@Synapse/chat/component.html.twig') }}
```

### 2. Utilisation programmatique (ChatService)

```php
// Dans un controller ou service
class MyController extends AbstractController
{
    public function __construct(
        private ChatService $chatService
    ) {}

    public function askAction(Request $request): JsonResponse
    {
        $result = $this->chatService->ask(
            message: $request->get('message'),
            options: ['stateless' => true]
        );

        return $this->json(['answer' => $result['answer']]);
    }
}
```

### 3. Interface d'administration

AccÃ¨s Ã  `/synapse/admin` pour :
- GÃ©rer les providers LLM et leurs credentials
- CrÃ©er et tester des presets de configuration
- Visualiser les conversations et analytics
- Configurer les paramÃ¨tres globaux
- Consulter les logs de debug

## ğŸ“š Documentation complÃ¨te

La documentation est organisÃ©e dans le dossier `docs/` :

- **[Configuration](docs/configuration.md)** â€” RÃ©fÃ©rence complÃ¨te de `synapse.yaml`, variables d'environnement, configuration des providers
- **[Usage](docs/usage.md)** â€” Guide d'utilisation : ChatService, crÃ©ation d'outils IA, events Symfony, personas
- **[IntÃ©gration des vues](docs/views.md)** â€” Templates Twig, layouts admin, personnalisation CSS
- **[Changelog](docs/changelog.md)** â€” Historique des versions

## ğŸ—ï¸ Architecture

### Couches de prompts

Le bundle gÃ¨re les prompts en 3 couches :

1. **Technical Prompt** (Interne) : RÃ¨gles de formatage et de rÃ©flexion native (via la config `thinking`)
2. **System Prompt** (Applicatif) : Contexte mÃ©tier configurÃ© dans l'admin ou le code
3. **User Prompt** : Demande directe de l'utilisateur

### Providers supportÃ©s

#### Google Vertex AI (Gemini)
- ModÃ¨les : `gemini-2.5-flash`, `gemini-2.5-pro`, etc.
- RÃ©gion : `europe-west1`, `europe-west4`, `us-central1`, etc.
- CapacitÃ©s : streaming, thinking natif, safety settings

#### OVH AI Endpoints (OpenAI-compatible)
- Endpoint customizable (dÃ©faut : `https://oai.endpoints.kepler.ai.cloud.ovh.net/v1`)
- Supports models OpenAI-compatible
- CapacitÃ©s : streaming, reasoning (thinking)

### Outils IA (Function Calling)

CrÃ©ez des outils personnalisÃ©s en implÃ©mentant `AiToolInterface` :

```php
class MaFonctionTool implements AiToolInterface
{
    public function getName(): string { return 'ma_fonction'; }
    public function getDescription(): string { return 'Description pour le LLM'; }
    public function getInputSchema(): array { return [...]; }
    public function execute(array $parameters): mixed { return [...]; }
}
```

Les outils sont automatiquement dÃ©couverts et disponibles pour le LLM.

## ğŸ§ª Tests

```bash
vendor/bin/phpunit
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Merci de :

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/ma-feature`)
3. Commit vos changements (`git commit -m 'Add ma feature'`)
4. Push vers la branche (`git push origin feature/ma-feature`)
5. Ouvrir une Pull Request

## ğŸ“ Changelog

Voir [Changelog](docs/changelog.md) pour l'historique des versions.

## ğŸ“„ Licence

PolyForm Noncommercial 1.0.0 - Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ™ CrÃ©dits

- **Design Chat** : InspirÃ© de l'interface Google Gemini
- **Icons** : [Lucide Icons](https://lucide.dev/)
- **Framework** : [Symfony](https://symfony.com/)
- **LLM Providers** : [Google Vertex AI](https://cloud.google.com/vertex-ai), [OVH AI Endpoints](https://docs.ovh.com/gb/en/ai-endpoints/)

---

**Made with â¤ï¸ by MakerLab**
